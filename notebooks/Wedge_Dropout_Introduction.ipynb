{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wedge Dropout Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoLrLZ0RlY5T"
      },
      "source": [
        "# Wedge Dropout\n",
        "*Wedge Dropout drives apart CNN feature maps which are too close together.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9rJE0scm_Ce"
      },
      "source": [
        "![wedge_4_100.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1m2kDyocl9I"
      },
      "source": [
        "\n",
        "## Abstract\n",
        "\n",
        "Wedge Dropout improves a CNN network by examining pairs of output feature maps and providing negative feedback if they are strongly correlated. \n",
        "Wedge Dropout is effective in almost all Convolutional Neural Network pipelines. Preliminary testing has shown that it can give a very slight improvement to model accuracy, generally 0.05% to 0.1%, in many different 1D, 2D and 3D CNN-based models. Usually no hyperparameter tuning is required to achieve this improvement. Wedge Dropout has no run-time overhead. Like other Dropout algorithms, it is only active during training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tya7rirIqap"
      },
      "source": [
        "\n",
        "## Abstract\n",
        "Convolutional Neural Networks (CNNs) operate by creating a set of independent *feature maps*. These are representations of various features that recur in the dataset used to train the network. Collectively, this set of feature maps serves as a description of the features of an image. The feature maps should be decorrelated- any redundancy in the feature maps degrades the predictive power of the network. \n",
        "\n",
        "Wedge Dropout is Dropout algorithm designed for convolutional networks. The algorithm measures the corelation among the set of feature maps generated by a CNN, and encourages any strongly correlated feature maps to become less correlated. It is effective in almost all convolutional Network pipelines, usually without any tuning of hyperparameters. Preliminary testing has shown that it can give a very slight improvement to model accuracy, generally 0.05% to 0.1%, in many different 1D, 2D and 3D CNN-based models. Wedge Dropout has no run-time overhead. Like other Dropout algorithms, it is only active during training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJtfWV1YpAT_"
      },
      "source": [
        "## Introduction\n",
        "Wedge Dropout is a Dropout algorithm tuned for convolutional networks.\n",
        "It improves a CNN by providing feedback during training; this is a recent innovation in Dropout algorithms.\n",
        "\n",
        "A CNN works by generating summaries based on an input dataset. These summaries are called \"feature maps\". For example, given a picture of a cat, one feature map outlines the head, another the eyes, a third the chin. Collectively they describe aspects of the cat. Feature maps should be independent- if they are correlated, or \"too similar\", the CNN describes fewer unique aspects than it could. \n",
        "\n",
        "The Wedge Dropout algorithm works by analyzing the final output of a convolutional neural network (CNN). Where Spatial Dropout zeroes out randomly chosen feature maps, Wedge Dropout analyzes randomly chosen pairs of feature maps and applies negative feedback to both when they are \"too similar\".\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el9QUGcHw-P5"
      },
      "source": [
        "![cat head](../pics/cat_feature_wedge_4.jpg)\n",
        "\n",
        "As an example, here is a picture of two different feature maps that were generated for the same image of a cat's face by a convolutional neural network. They \"outline\" the contours of the side of the cat's head, where it joins the neck. Note that the two feature maps are very similar, but are not the same. Since these feature maps are so similar, they are redundant in function. Wedge Dropout will find this pair of feature maps during training, and via negative feedback will drive them apart so that they describe slightly different aspects of this part of the cat's body. The effect is small but measurable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Y1vWhAEyhX"
      },
      "source": [
        "## Similar Work\n",
        "Wedge Dropout is a combination of two recent trends in dropout research: CNN-specific dropout strategies and critiquing feature maps.\n",
        "### CNN-Specific Dropout Strategies\n",
        "SpatialDropout and Dropblock are dropout strategies specifically designed around the nature of CNN feature maps. CNN feature maps are strongly correlated within the feature map, but different feature maps are not strongly correlated. \n",
        "#### *SpatialDropout*\n",
        "SpatialDropout zeroes out randomly chosen feature maps, to discourage them from becoming too correlated. It is best used right after the first convolutional layer.\n",
        "#### *DropBlock*\n",
        "DropBlock randomly chooses sub-rectangles in feature maps and randomly zeroes them out. Again, this discourages feature maps from becoming strongly correlated. It is not clear where it should be used in the network.\n",
        "### Critiquing Feature Maps\n",
        "It is possible to analyze feature maps and provide feedback when some of them become non-performant. This seems to be a recent invention.\n",
        "\n",
        "Under this method, a layer scores all of the feature maps generated for an image. The score determines whether the feature map will be interfered with in some way. It could be zeroed out entirely, or the scoring function could indicate a specific region of the feature map that should be disrupted. We will examine two of these, CamDrop and InfoDrop.\n",
        "\n",
        "#### *CamDrop*\n",
        "In CamDrop, feature maps are analyzed and then a rectangular region is zeroed out in multiple, but not all, feature maps. This clearly can discourage correlation.\n",
        "#### *InfoDrop*\n",
        "CNNs are notorious for fixating on textural features to the detriment of spatial features. InfoDrop (Informative Dropout) addresses this by finding regions of a feature map which correspond to a texture in the original image. It then applies negative feedback via \"fuzzing\" the offending section of the feature map.\n",
        "### Summary\n",
        "\n",
        "In a sense, Wedge Dropout is to Spatial Dropout as CamDrop is to DropBlock: it replaces randomized dropout with a scoring mechanism based on analyzing feature maps. Wedge Dropout was directly inspired by SpatialDropout and CamDrop.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQWWMkx5Ff36"
      },
      "source": [
        "## Algorithms\n",
        "CNN feature maps generally have a low-valued \"background\" and high-valued \"hills\", where the hills are the feature(s) found in the original image. Two algorithms were investigated for Wedge Dropout's analysis phase. Both specifically ignore the background and only compare the hills, by using the mean value. It is not clear whether either algorithm is more robust across different CNN use cases.\n",
        "### Direct Comparison\n",
        "This algorithm isolates the cells in each feature map which are above its mean value, and then compares individual values across both feature maps cell by cell in a simple Boolean AND operation. This counts the number of cells in both feature maps that tend to find the same feature. If this count is above a certain percentage of the total number of cells in the feature map, both feature maps are zeroed out.\n",
        "### Normalize and Multiply\n",
        "This algorithm normalizes both feature maps to a range from 0.0 to 1.0, multiplies the two feature maps cellwise (Hadamard matrix multiplication), and counts the number of values above the mean of the resulting output. Again, if more than a certain percentage are above the mean, both feature maps are zeroed out.\n",
        "\n",
        "Following are implementations of each algorithm in Python, using the following feature maps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pap-WgK5hE1p",
        "outputId": "492ef618-fc04-426d-8751-a6880d9d34e0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "fmap1 = np.asarray([[1,2],[3,4]])\n",
        "fmap2 = np.asarray([[3,1],[4, 9]])\n",
        "\n",
        "print('Feature Map #1')\n",
        "print(fmap1)\n",
        "print('Feature Map #2')\n",
        "print(fmap2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Map #1\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "Feature Map #2\n",
            "[[3 1]\n",
            " [4 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvmrcvQ8uvLw",
        "outputId": "d7edb1a0-a399-4a08-976e-ab65ec353ea7"
      },
      "source": [
        "def similarity_direct_comparison(img1, img2):\n",
        "    mean1 = np.mean(img1)\n",
        "    mean2 = np.mean(img2)\n",
        "\n",
        "    visible1 = img1 > mean1\n",
        "    visible2 = img2 > mean2\n",
        "\n",
        "    correlated = visible1 == visible2\n",
        "\n",
        "    percentage = sum(correlated.flatten()) / len(img1.flatten())\n",
        "\n",
        "    return percentage\n",
        "\n",
        "def similarity_multiply(img1, img2):\n",
        "    zero1 = img1 - np.min(img1)\n",
        "    zero2 = img2 - np.min(img2)\n",
        "    norm1 = zero1 / (np.linalg.norm(zero1) + 0.0001)\n",
        "    norm2 = zero2 / (np.linalg.norm(zero2) + 0.0001)\n",
        "    # normalized maps are now in the same range\n",
        "    mult = norm1 * norm2\n",
        "    avg = np.median(mult)\n",
        "    correlated = mult > avg\n",
        "\n",
        "    percentage = sum(correlated.flatten()) / len(img1.flatten())\n",
        "    return percentage\n",
        "\n",
        "percentage1 = similarity_direct_comparison(fmap1, fmap2)\n",
        "print('Direct Comparison similarity score:', percentage1)\n",
        "percentage2 = similarity_multiply(fmap1, fmap2)\n",
        "print('Normalize and Multiply similarity score:', percentage2)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Direct Comparison similarity score: 0.75\n",
            "Normalize and Multiply similarity score: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OsHP8gS4daO"
      },
      "source": [
        "We can see that the two algorithms provide different interpretations of 'correlated'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29nNej-P34l"
      },
      "source": [
        "# Results\n",
        "Results for several different Keras examples, rewritten for tuning, and with a head-to-head comparison of with and without Wedge Dropout. \n",
        "\n",
        "\n",
        "<table>\n",
        "<caption>Table 1 - Measurements of the impact of Wedge Dropout on loss and accuracy values</caption>\n",
        "<tr><th>Keras Example</th>\n",
        "<th>Type</th>\n",
        "<th>Loss base</th>\n",
        "<th>Loss test</th>\n",
        "<th></th>\n",
        "<th>Accuracy base</th>\n",
        "<th>Accuracy test</th>\n",
        "<th>Accuracy Delta %</th>\n",
        "<th>Notes</th>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/Wedge2D_Demo_vae.ipynb\">VAE with WedgeDropout in decoder</a></td>\n",
        "  <td>Base</td>\n",
        "  <td>6.8831</td>\n",
        "  <td>6.0036</td>\n",
        "  <td> </td>\n",
        "  <td>0.8112</td>\n",
        "  <td>0.8261</td>\n",
        "  <td>1.49%</td>\n",
        "  <td> </td>\n",
        "</tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout1D_Demo_timeseries_anomaly_detection.ipynb\">Timeseries anomaly detection using an Autoencoder</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.0049</td>\n",
        "  <td>0.0029</td>\n",
        "  <td> </td>\n",
        "  <td/><td/><td/><td/>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout1D_Demo_timeseries_classification_from_scratch.ipynb\">Timeseries classification from scratch</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.1921</td>\n",
        "  <td>0.1059</td>\n",
        "  <td> </td>\n",
        "  <td>0.9189</td>\n",
        "  <td>0.9621</td>\n",
        "  <td>4.32%</td>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout1D_Demo_transformer_asr.ipynb\">Automatic Speech Recognition with Transformers</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.7396</td>\n",
        "  <td>0.6854</td>\n",
        "  <td> </td>\n",
        "  <td/><td/><td/><td/>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/Wedge_oxford_pets_image_segmentation.ipynb\">Image segmentation with a U-Net-like architecture</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.4046</td>\n",
        "  <td>0.4180</td>\n",
        "  <td> </td>\n",
        "  <td>0.3018</td>\n",
        "  <td>0.3326</td>\n",
        "  <td>3.08%</td>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout2D_demo_xray_classification_with_tpus.ipynb\">Pneumonia Classification on TPU</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.1404</td>\n",
        "  <td>0.0935</td>\n",
        "  <td> </td>\n",
        "  <td>0.9651</td>\n",
        "  <td>0.9738</td>\n",
        "  <td>0.87%</td>\n",
        "  <td/>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout1D_demo_pointnet.ipynb\">Point cloud classification with PointNet</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.6674</td>\n",
        "  <td>0.7731</td>\n",
        "  <td> </td>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropoutLSTM2D_next_frame_with_conv_lstm.ipynb\">Next-frame prediction with Conv-LSTM</a></td>\n",
        "  <td>Validation</td>\n",
        "  <td>0.0170</td>\n",
        "  <td>0.0054</td>\n",
        "  <td> </td>\n",
        "  <td>0.9955</td>\n",
        "  <td>0.9983</td>\n",
        "  <td>0.23%</td>  \n",
        "  <td>700 epochs,stopped at 2300 epochs</td>\n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout2D_captcha_ocr.ipynb\">OCR model for reading Captchas</a></td>\n",
        "  <td>Loss</td>\n",
        "  <td>0.2946</td>\n",
        "  <td>0.2465</td>\n",
        "  <td> </td>\n",
        "  <td> </td>\n",
        "  <td> </td>\n",
        "  <td> </td>  \n",
        "</tr>\n",
        "<tr>\n",
        " <td><a href=\"https://github.com/LanceNorskog/keras-wedge/blob/main/notebooks/WedgeDropout2D_siamese_contrastive.ipynb\">Image similarity using Siamese plus contrastive</a></td>\n",
        "  <td>Loss</td>\n",
        "  <td>0.0134</td>\n",
        "  <td>0.0128</td>\n",
        "  <td> </td>\n",
        "  <td>0.9833</td>\n",
        "  <td>0.9840</td>\n",
        "  <td>0.07%</td>  \n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "loss: 0.0134 - accuracy: 0.9833\n",
        "0128 9840"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPWVk9BrJ8da"
      },
      "source": [
        "Training notes:\n",
        "* The Keras examples are just that, examples. They are not intended as production models. There are various problems that make it harder to test Wedge Dropout in an a/b test:\n",
        "** Some models do not include an accuracy measurement. Loss is a unitless number. Wedge Dropout models usually have increased loss at the beginning and decreased loss at the end, compared to the base model. This is due to large amounts of negative feedback at the beginning, and overall higher quality of the model at the end.\n",
        "** Some models do not include a validation dataset.\n",
        "** Some models have very small datasets, or are a \"toy\" problem.\n",
        "** The models are generally shallow.\n",
        "*** This is important because Wedge Dropout does not do well on tests of deeper networks. It is possible that the negative feedback is not apportioned well across deep stacks of convolutions, or in recurrent networks.\n",
        "* Wedge Dropout only does well at the end of a model. When the CNN chain ends in the middle of the model, for example the Siamese Contrastive Similarity model, it does not give improvements.\n",
        "* Wedge Dropout can increase the loss, to compensate for this some models needed a smaller learning rate for the Wedge Dropout version.\n",
        "* Wedge Dropout works better with large batches, so most of the examples are changed to large memory configurations with batch sizes as large as possible. This also improves BatchNormalization, so it benefits both base and test versions.\n",
        "* Earlier versions of Tensorflow could have much longer times for the compilation graph, and longer execution times, when the Wedge Dropout layer is added. This is not as visible with 2.5.0.\n",
        "* Later versions of Tensorflow seem to have better performance (predictive power) for the original models, and the difference made by Wedge Dropout was not as visible. \n",
        "* The WedgeDropout layer code triggered a TPU compilation error in earlier Tensorflow versions. It works starting with Tensorflow 2.5.0, and only without a final \"odd lot\" batch size. (It does not work in the early release of 2.6.0-rc1, and an issues is filed with the Keras project.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taWg9w49KPq2"
      },
      "source": [
        "# Usage\n",
        "Wedge Dropout operates by critiquing the values created by the CNN pipeline, and is best used at the end of a pipeline of CNN layers. \n",
        "\n",
        "*Note: Lift a standard CNN diagram and poke in a Wedge Dropout layer right before the final Dense/GlobalAveragePooling layer.*\n",
        "\n",
        "Wedge Dropout only has one hyperparameter, the similarity coefficient. Preliminary testing on many different 1D, 2D and 3D CNN networks has shown that one value is optimal for almost all applications: 0.5 for the Direct Comparison algorithm, and 0.65 for the Normalize and Multiply algorithm.\n",
        "\n",
        "# Batch-wise Operation and Batch Normalization\n",
        "It has proven effective to apply Wedge Dropout to all of the feature maps for a pair of random indexes, and then do a simple voting algorithm on the results. For example, if the batch size is 32, then if 16 pairs of feature maps are \"too similar\", then all 32 feature maps are zeroed out. If only 15 pairs are too similar, none of the feature maps are zeroed out.\n",
        "\n",
        "When operating per sample, Wedge Dropout critiques a pair of feature maps. In batch-wise operation, Wedge Dropout critiques the engine, or causal chain, that created the feature maps. \n",
        "\n",
        "Batch Normalization is a proven method of improving a CNN model, and is used in most reference architectures except image generators. Batch Normalization's performance improves as the batch size increases. Wedge Dropout's performance also increases as batch size increases, so it is a good match for existing CNN architectures. Like Spatial Dropout and other CNN-specific Dropout algorithms, do not place a Batch Normalization layer after a Wedge Dropout layer. Wedge Dropout works well after a Batch Normalization layer. All successful tests have placed the Wedge Dropout layer right before the final summarization layer, usually a Dense or GlobalAveragePooling layer. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js6VOVdNPNnR"
      },
      "source": [
        "# Further Research\n",
        "## Algorithms\n",
        "* There may be other similarity functions appropriate for CNN feature maps.\n",
        "* There may be a better technique than 'median' or 'mean' for determining the \"interesting\" parts of a feature map.\n",
        "\n",
        "## Dropout Style\n",
        "\"Slice Dropout\" [ https://arxiv.org/pdf/2006.16571.pdf ], a variant of Spatial Dropout, zeroes out only one half of a feature map instead of the entire feature map. A more complex version of Wedge Dropout's feature map comparison could decide that all of the offending cells are concentrated on one side of the feature map, or even just one quadrant. It would choose to zero out only that area.\n",
        "\n",
        "It is possible that zeroing out values is not the only way to affect training. There may be ways to do a random fill which do not disrupt the operation of Batch Normalization. InfoDrop uses a selective fuzzing technique to disrupt feature maps which respond to textures. This might be useful to Wedge Dropout.\n",
        "\n",
        "### Feature Maps and Attention Heads\n",
        "The multi-head attention architecture [ https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf ] creates multiple \"answer\" vectors of the same size, and combines them with addition. This set of vectors shares a property with a set of feature maps: the information within the vector is strongly correlated, but information across vectors should not be correlated. If the information is correlated across attention heads, the attention heads are learning the same answer set. It is possible that Wedge Dropout, or even Spatial Dropout, will improve the function of a multi-head attention model, given an appropriate similarity function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwlZGeKuPa45"
      },
      "source": [
        "# Concluding Remarks\n",
        "## Time added to training\n",
        "The Wedge Dropout algorithm can add a noticeable increase in tensor graph compilation time, and training time per epoch. For example, the final phase of EfficientNet \"Zero\" generates 1024 feature maps, and then applies GlobalAveragePooling to those. Wedge Dropout was most effective when inserted between the final convolution layer and the GlobalAveralPooling layer. Adding Wedge Dropout increased the tensor graph compilation phase by 20%, and added 10%-15% to the running time for each epoch. This effect seems to be reduced in recent Tensorflow releases.\n",
        "\n",
        "Wedge Dropout is not active during prediction, and does not contribute any values that need to be loaded for a model. The Wedge Dropout layer can be stripped out of an inference-only version of the model. (As it happens, the Tensorflow *smart_cond()* feature that is used for the *trainable* flag requires that the analysis code be executed and ignored during production. Thus, a Tensorflow production model really should be a separate architecture based on the training version!)\n",
        "\n",
        "## Quantity of feature maps\n",
        "The algorithm simply chooses N/2 pairs of feature maps on each epoch. In networks which create large numbers of feature maps, it is possible that Wedge Dropout should apply the similarity function to more pairs. For example, N/8 * log(N) would give a similar number for small networks but an interesting number of comparisons for larger networks.\n",
        "\n",
        "Since Wedge Dropout makes feature maps (slightly) more expressive, it is possible that it could allow a model to achieve the required performance with fewer feature maps.\n",
        "\n",
        "## Batch-oriented Operation\n",
        "We have found it worthwhile compare the same pair of feature maps for every sample in a batch, and apply simple voting to decide whether to apply negative feedback to all of the samples. It is useful to consider the CNN as an engine that creates feature maps: by doing this we apply negative feedback at a feature map level, not per sample. This voting system increases in power as the batch size increases. BatchNormalization also improves with batch size, so this is a synergetic design. We should note that zeroing out the feature maps \"confuses\" BatchNormalization when placed before BatchNormalization, and so there should be no BatchNormalization layers after the Wedge Dropout layer.\n",
        "\n",
        "## Utility\n",
        "Wedge Dropout is not needed for any image architecture. However, given the lack of complex hyperparameters and simplicity of application, it will probably improve most production uses of CNNs.\n",
        "It has been tested with many example networks in the Keras documentation, and worked in all Conv1D, Conv2D and Conv3D-based applications. It did not improve a multi-layer fully trained networks (EfficientNet Level 0), but did improve an application which uses pre-trained ImageNet layers. It also did not help with LSTM2D. Given the lack of complex hyperparameters and simplicity of application, it should be useful in many production applications of convolutional neural nets.\n",
        "\n",
        "Since Wedge Dropout works by critiquing the output of a CNN, it is possible that its feedback only works in a simple causal chain. It is possible that the causal graph of feature map creation is turbid in deep networks and 2D LSTMs; perhaps some other method of negative feedback would be more effective. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5bdsxOtUXM2"
      },
      "source": [
        "# Conclusion\n",
        "Wedge Dropout is a very robust technique for improving the operation of almost any convolutional neural network. It critiques the set of feature maps created by a CNN with a scoring function (similarity of pairs) and applies negative feedback to improve the decorrelation of feature maps. It usually requires no hyperparameter tuning- it has been tested in 1D, 2D and 3D networks and the default tuning parameter was optimal. With some care, it coexists well with standard CNN techniques like BatchNormalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdHlFun6Layc"
      },
      "source": [
        "# Citations\n",
        "[ CNN ](https://arxiv.org/pdf/1404.7828.pdf)\n",
        "\n",
        "[ Dropout ](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
        "\n",
        "[ CamDrop ](https://dl.acm.org/doi/10.1145/3357384.3357999)\n",
        "\n",
        "[ DropBlock ](https://papers.nips.cc/paper/8271-dropblock-a-regularization-method-for-convolutional-networks.pdf)\n",
        "\n",
        "[ InfoDrop ](https://arxiv.org/abs/2008.04254)\n",
        "\n",
        "[ SpatialDropout paper ](https://arxiv.org/pdf/1411.4280.pdf)\n",
        "\n",
        "[ SpatialDropout Keras man page ](https://keras.io/api/layers/regularization_layers/spatial_dropout2d/)"
      ]
    }
  ]
}