{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wedge- oxford_pets_image_segmentation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hagnL1_ktELY"
      },
      "source": [
        "# Image segmentation with a U-Net-like architecture\n",
        "Rebuilt to demo validity of Wedge Dropout, and compare it to Spatial Dropout.\n",
        "\n",
        "Original is: https://keras.io/examples/vision/oxford_pets_image_segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C98e--9mVYD4",
        "outputId": "1a6140a8-4d34-47f0-a42c-d51751686877"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install -q tensorflow==2.3.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.3.3\n",
            "Uninstalling tensorflow-2.3.3:\n",
            "  Successfully uninstalled tensorflow-2.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpmOjiHIxLdv"
      },
      "source": [
        "!wget -q -nc http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget -q -nc http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6x42FhkxLdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6b6415-1fc2-432a-f33e-60d2dc0a490e"
      },
      "source": [
        "import os\n",
        "\n",
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "img_size = (160, 160)\n",
        "num_classes = 4\n",
        "batch_size = 96\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "    print(input_path, \"|\", target_path)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 7390\n",
            "images/Abyssinian_1.jpg | annotations/trimaps/Abyssinian_1.png\n",
            "images/Abyssinian_10.jpg | annotations/trimaps/Abyssinian_10.png\n",
            "images/Abyssinian_100.jpg | annotations/trimaps/Abyssinian_100.png\n",
            "images/Abyssinian_101.jpg | annotations/trimaps/Abyssinian_101.png\n",
            "images/Abyssinian_102.jpg | annotations/trimaps/Abyssinian_102.png\n",
            "images/Abyssinian_103.jpg | annotations/trimaps/Abyssinian_103.png\n",
            "images/Abyssinian_104.jpg | annotations/trimaps/Abyssinian_104.png\n",
            "images/Abyssinian_105.jpg | annotations/trimaps/Abyssinian_105.png\n",
            "images/Abyssinian_106.jpg | annotations/trimaps/Abyssinian_106.png\n",
            "images/Abyssinian_107.jpg | annotations/trimaps/Abyssinian_107.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er0hnZpqxLd7"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "class OxfordPets(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size)\n",
        "            x[j] = img\n",
        "        y = np.zeros((batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
        "            y[j] = np.expand_dims(img, 2)\n",
        "        return x / 255, y - 1\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl81iFvqOUig"
      },
      "source": [
        "# Wedge2D Dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fN0dcOM-Xyy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D897MxAgv8Fy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e44086c-2498-4ecf-8e43-376de6b669ed"
      },
      "source": [
        "!pip uninstall -y keras-wedge-dropout\n",
        "!pip install -q git+https://github.com/LanceNorskog/keras-wedge.git\n",
        "import numpy as np\n",
        "from keras_wedge_dropout import WedgeDropout2D"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: keras-wedge-dropout 0.1.0\n",
            "Uninstalling keras-wedge-dropout-0.1.0:\n",
            "  Successfully uninstalled keras-wedge-dropout-0.1.0\n",
            "  Building wheel for keras-wedge-dropout (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzrKgPOkxLd-"
      },
      "source": [
        "## Perpare U-Net Xception-style model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncweKfbxLd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8299c55-424f-4a83-a96f-5001f8ce3c69"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "he = 'he_normal'\n",
        "def get_model(img_size, num_classes, wedgeDropout=False):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\", kernel_initializer = he)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for step, filters in enumerate([64, 128, 256]):\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\", kernel_initializer = he)(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for step, filters in enumerate([256, 128, 64, 32]):\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\", kernel_initializer = he)(residual)\n",
        "        x = layers.add([x, residual], name='final_add_'+str(step))  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    wedge = None\n",
        "    if wedgeDropout:\n",
        "        x = WedgeDropout2D(0.65, batchwise=True)(x)\n",
        "        wedge = x\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\", name='output', kernel_initializer = he)(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model, wedge\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model, _ = get_model(img_size, num_classes)\n",
        "model.summary()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        final_add_3[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR243W93xLeC"
      },
      "source": [
        "## Set aside a validation split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCCk3rxuxLeC"
      },
      "source": [
        "import random\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "val_samples = 1000\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_img_paths)\n",
        "train_input_img_paths = input_img_paths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_img_paths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = OxfordPets(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths\n",
        ")\n",
        "val_gen = OxfordPets(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD_s4NmSxLeG"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PfqUOM3xLeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f385371c-1337-4850-8fea-f59ae892800e"
      },
      "source": [
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 100\n",
        "model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model.evaluate(val_gen))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1084s vs `on_train_batch_end` time: 0.3220s). Check your callbacks.\n",
            "66/66 - 36s - loss: 4.1725 - accuracy: 0.3018 - val_loss: 5.1031 - val_accuracy: 0.0101\n",
            "Epoch 2/100\n",
            "66/66 - 35s - loss: 0.8967 - accuracy: 0.3046 - val_loss: 1.6175 - val_accuracy: 0.0915\n",
            "Epoch 3/100\n",
            "66/66 - 33s - loss: 0.7542 - accuracy: 0.3058 - val_loss: 1.5730 - val_accuracy: 2.9553e-04\n",
            "Epoch 4/100\n",
            "66/66 - 34s - loss: 0.6245 - accuracy: 0.3135 - val_loss: 1.3110 - val_accuracy: 6.3745e-04\n",
            "Epoch 5/100\n",
            "66/66 - 33s - loss: 0.5496 - accuracy: 0.3099 - val_loss: 1.1826 - val_accuracy: 0.0071\n",
            "Epoch 6/100\n",
            "66/66 - 35s - loss: 0.4955 - accuracy: 0.3081 - val_loss: 0.8450 - val_accuracy: 0.0588\n",
            "Epoch 7/100\n",
            "66/66 - 33s - loss: 0.4660 - accuracy: 0.3107 - val_loss: 0.5835 - val_accuracy: 0.2210\n",
            "Epoch 8/100\n",
            "66/66 - 35s - loss: 0.4230 - accuracy: 0.3090 - val_loss: 0.4825 - val_accuracy: 0.2514\n",
            "Epoch 9/100\n",
            "66/66 - 33s - loss: 0.4007 - accuracy: 0.3103 - val_loss: 0.4455 - val_accuracy: 0.2948\n",
            "Epoch 10/100\n",
            "66/66 - 35s - loss: 0.3907 - accuracy: 0.3089 - val_loss: 0.4763 - val_accuracy: 0.2615\n",
            "Epoch 11/100\n",
            "66/66 - 34s - loss: 0.3471 - accuracy: 0.3087 - val_loss: 0.4175 - val_accuracy: 0.3381\n",
            "Epoch 12/100\n",
            "66/66 - 34s - loss: 0.3338 - accuracy: 0.3083 - val_loss: 0.4421 - val_accuracy: 0.2972\n",
            "Epoch 13/100\n",
            "66/66 - 34s - loss: 0.3139 - accuracy: 0.3074 - val_loss: 0.4194 - val_accuracy: 0.3127\n",
            "Epoch 14/100\n",
            "66/66 - 34s - loss: 0.2995 - accuracy: 0.3071 - val_loss: 0.4046 - val_accuracy: 0.3018\n",
            "Epoch 15/100\n",
            "66/66 - 34s - loss: 0.2761 - accuracy: 0.3070 - val_loss: 0.4167 - val_accuracy: 0.3064\n",
            "Epoch 16/100\n",
            "66/66 - 34s - loss: 0.2655 - accuracy: 0.3062 - val_loss: 0.4659 - val_accuracy: 0.3151\n",
            "Epoch 17/100\n",
            "66/66 - 34s - loss: 0.2492 - accuracy: 0.3060 - val_loss: 0.4433 - val_accuracy: 0.3108\n",
            "Epoch 18/100\n",
            "66/66 - 34s - loss: 0.2331 - accuracy: 0.3056 - val_loss: 0.4410 - val_accuracy: 0.2771\n",
            "Epoch 19/100\n",
            "66/66 - 33s - loss: 0.3263 - accuracy: 0.3051 - val_loss: 0.4225 - val_accuracy: 0.2988\n",
            "Epoch 20/100\n",
            "66/66 - 34s - loss: 0.2212 - accuracy: 0.3048 - val_loss: 0.5006 - val_accuracy: 0.2761\n",
            "Epoch 21/100\n",
            "66/66 - 34s - loss: 0.2121 - accuracy: 0.3043 - val_loss: 0.5044 - val_accuracy: 0.2659\n",
            "Epoch 22/100\n",
            "66/66 - 33s - loss: 0.2063 - accuracy: 0.3037 - val_loss: 0.5688 - val_accuracy: 0.3471\n",
            "Epoch 23/100\n",
            "66/66 - 34s - loss: 0.2037 - accuracy: 0.3034 - val_loss: 0.5927 - val_accuracy: 0.3428\n",
            "Epoch 24/100\n",
            "66/66 - 33s - loss: 0.1917 - accuracy: 0.3032 - val_loss: 0.5327 - val_accuracy: 0.2800\n",
            "10/10 [==============================] - 4s 412ms/step - loss: 0.4046 - accuracy: 0.3018\n",
            "[0.4045927822589874, 0.3018067479133606]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TqNBziQPTrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd1fcb9-bc81-4157-efb0-a0d01010beea"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, _ = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1514s vs `on_train_batch_end` time: 0.3233s). Check your callbacks.\n",
            "66/66 - 36s - loss: 5.1071 - accuracy: 0.2382 - val_loss: 6.6786 - val_accuracy: 1.0946e-05\n",
            "Epoch 2/100\n",
            "66/66 - 35s - loss: 1.0482 - accuracy: 0.3104 - val_loss: 2.4768 - val_accuracy: 0.0118\n",
            "Epoch 3/100\n",
            "66/66 - 34s - loss: 0.7762 - accuracy: 0.3085 - val_loss: 1.8213 - val_accuracy: 2.6005e-04\n",
            "Epoch 4/100\n",
            "66/66 - 35s - loss: 0.6629 - accuracy: 0.3137 - val_loss: 1.6317 - val_accuracy: 1.2366e-04\n",
            "Epoch 5/100\n",
            "66/66 - 35s - loss: 0.5572 - accuracy: 0.3097 - val_loss: 2.0307 - val_accuracy: 0.0014\n",
            "Epoch 6/100\n",
            "66/66 - 34s - loss: 0.5094 - accuracy: 0.3126 - val_loss: 0.9470 - val_accuracy: 0.0433\n",
            "Epoch 7/100\n",
            "66/66 - 35s - loss: 0.4698 - accuracy: 0.3122 - val_loss: 0.5508 - val_accuracy: 0.2704\n",
            "Epoch 8/100\n",
            "66/66 - 34s - loss: 0.4409 - accuracy: 0.3107 - val_loss: 0.4789 - val_accuracy: 0.3355\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4086 - accuracy: 0.3124 - val_loss: 0.4535 - val_accuracy: 0.3054\n",
            "Epoch 10/100\n",
            "66/66 - 34s - loss: 0.3816 - accuracy: 0.3099 - val_loss: 0.4772 - val_accuracy: 0.3169\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3571 - accuracy: 0.3102 - val_loss: 0.4411 - val_accuracy: 0.2812\n",
            "Epoch 12/100\n",
            "66/66 - 34s - loss: 0.3346 - accuracy: 0.3092 - val_loss: 0.4857 - val_accuracy: 0.3541\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3108 - accuracy: 0.3084 - val_loss: 0.4696 - val_accuracy: 0.3200\n",
            "Epoch 14/100\n",
            "66/66 - 35s - loss: 0.2970 - accuracy: 0.3083 - val_loss: 0.4189 - val_accuracy: 0.3121\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.2774 - accuracy: 0.3072 - val_loss: 0.4127 - val_accuracy: 0.3252\n",
            "Epoch 16/100\n",
            "66/66 - 34s - loss: 0.2669 - accuracy: 0.3071 - val_loss: 0.4384 - val_accuracy: 0.3194\n",
            "Epoch 17/100\n",
            "66/66 - 35s - loss: 0.2501 - accuracy: 0.3066 - val_loss: 0.4288 - val_accuracy: 0.3224\n",
            "Epoch 18/100\n",
            "66/66 - 34s - loss: 0.2413 - accuracy: 0.3063 - val_loss: 0.4303 - val_accuracy: 0.2984\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2350 - accuracy: 0.3051 - val_loss: 0.4387 - val_accuracy: 0.2764\n",
            "Epoch 20/100\n",
            "66/66 - 34s - loss: 0.2173 - accuracy: 0.3049 - val_loss: 0.5517 - val_accuracy: 0.3721\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2101 - accuracy: 0.3044 - val_loss: 0.4626 - val_accuracy: 0.2608\n",
            "Epoch 22/100\n",
            "66/66 - 34s - loss: 0.2078 - accuracy: 0.3041 - val_loss: 0.4588 - val_accuracy: 0.2938\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2023 - accuracy: 0.3039 - val_loss: 0.4476 - val_accuracy: 0.3028\n",
            "Epoch 24/100\n",
            "66/66 - 35s - loss: 0.1904 - accuracy: 0.3034 - val_loss: 0.5635 - val_accuracy: 0.2499\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.2420 - accuracy: 0.3030 - val_loss: 0.4710 - val_accuracy: 0.3122\n",
            "10/10 [==============================] - 4s 417ms/step - loss: 0.4127 - accuracy: 0.3252\n",
            "[0.41272249817848206, 0.32523539662361145]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869amnT6-3Zk",
        "outputId": "65255dd0-f6ed-4f46-f889-29c114728adf"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout disabled, then turn it on.\n",
        "starting_epochs=5\n",
        "wedge.trainable = False\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = True\n",
        "print('WedgeDropout2D enabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1407s vs `on_train_batch_end` time: 0.3059s). Check your callbacks.\n",
            "66/66 - 30s - loss: 5.9456 - accuracy: 0.1644\n",
            "Epoch 2/5\n",
            "66/66 - 31s - loss: 2.2079 - accuracy: 0.3215\n",
            "Epoch 3/5\n",
            "66/66 - 30s - loss: 0.8195 - accuracy: 0.3011\n",
            "Epoch 4/5\n",
            "66/66 - 30s - loss: 0.6340 - accuracy: 0.3133\n",
            "Epoch 5/5\n",
            "66/66 - 30s - loss: 0.5759 - accuracy: 0.3095\n",
            "WedgeDropout2D enabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1327s vs `on_train_batch_end` time: 0.3227s). Check your callbacks.\n",
            "66/66 - 35s - loss: 0.5419 - accuracy: 0.3057 - val_loss: 1.2258 - val_accuracy: 0.0086\n",
            "Epoch 7/100\n",
            "66/66 - 35s - loss: 0.4692 - accuracy: 0.3119 - val_loss: 0.8447 - val_accuracy: 0.1072\n",
            "Epoch 8/100\n",
            "66/66 - 34s - loss: 0.4539 - accuracy: 0.3103 - val_loss: 0.5315 - val_accuracy: 0.2452\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4194 - accuracy: 0.3115 - val_loss: 0.4494 - val_accuracy: 0.3182\n",
            "Epoch 10/100\n",
            "66/66 - 34s - loss: 0.3952 - accuracy: 0.3115 - val_loss: 0.4384 - val_accuracy: 0.2819\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3701 - accuracy: 0.3113 - val_loss: 0.4445 - val_accuracy: 0.3140\n",
            "Epoch 12/100\n",
            "66/66 - 34s - loss: 0.3473 - accuracy: 0.3108 - val_loss: 0.4181 - val_accuracy: 0.2838\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3261 - accuracy: 0.3094 - val_loss: 0.4211 - val_accuracy: 0.2965\n",
            "Epoch 14/100\n",
            "66/66 - 34s - loss: 0.3071 - accuracy: 0.3095 - val_loss: 0.4278 - val_accuracy: 0.3006\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.2893 - accuracy: 0.3087 - val_loss: 0.4386 - val_accuracy: 0.3115\n",
            "Epoch 16/100\n",
            "66/66 - 35s - loss: 0.2758 - accuracy: 0.3079 - val_loss: 0.4075 - val_accuracy: 0.3062\n",
            "Epoch 17/100\n",
            "66/66 - 35s - loss: 0.2595 - accuracy: 0.3077 - val_loss: 0.5931 - val_accuracy: 0.3779\n",
            "Epoch 18/100\n",
            "66/66 - 35s - loss: 0.2514 - accuracy: 0.3071 - val_loss: 0.4235 - val_accuracy: 0.3231\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2353 - accuracy: 0.3067 - val_loss: 0.4359 - val_accuracy: 0.3124\n",
            "Epoch 20/100\n",
            "66/66 - 35s - loss: 0.2283 - accuracy: 0.3061 - val_loss: 0.4330 - val_accuracy: 0.3116\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2221 - accuracy: 0.3053 - val_loss: 0.4336 - val_accuracy: 0.3239\n",
            "Epoch 22/100\n",
            "66/66 - 34s - loss: 0.2080 - accuracy: 0.3051 - val_loss: 0.4599 - val_accuracy: 0.2841\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2043 - accuracy: 0.3043 - val_loss: 0.4546 - val_accuracy: 0.2937\n",
            "Epoch 24/100\n",
            "66/66 - 34s - loss: 0.1945 - accuracy: 0.3037 - val_loss: 0.4560 - val_accuracy: 0.3291\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.1884 - accuracy: 0.3038 - val_loss: 0.5441 - val_accuracy: 0.3393\n",
            "Epoch 26/100\n",
            "66/66 - 35s - loss: 0.1859 - accuracy: 0.3031 - val_loss: 0.4862 - val_accuracy: 0.2967\n",
            "10/10 [==============================] - 4s 389ms/step - loss: 0.4075 - accuracy: 0.3062\n",
            "[0.4074603319168091, 0.3061758279800415]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUqYFn5TtXmJ",
        "outputId": "f5b4f41b-8121-4313-deb8-d688c1062446"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"adam\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout disabled, then turn it on.\n",
        "starting_epochs=5\n",
        "wedge.trainable = False\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = True\n",
        "print('WedgeDropout2D enabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1715s vs `on_train_batch_end` time: 0.3245s). Check your callbacks.\n",
            "66/66 - 30s - loss: 3.3135 - accuracy: 0.3335\n",
            "Epoch 2/5\n",
            "66/66 - 31s - loss: 2.2521 - accuracy: 0.3383\n",
            "Epoch 3/5\n",
            "66/66 - 30s - loss: 1.3654 - accuracy: 0.3120\n",
            "Epoch 4/5\n",
            "66/66 - 31s - loss: 0.5815 - accuracy: 0.3140\n",
            "Epoch 5/5\n",
            "66/66 - 30s - loss: 0.5316 - accuracy: 0.3155\n",
            "WedgeDropout2D enabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1866s vs `on_train_batch_end` time: 0.3082s). Check your callbacks.\n",
            "66/66 - 36s - loss: 0.5015 - accuracy: 0.3161 - val_loss: 1.0507 - val_accuracy: 0.0431\n",
            "Epoch 7/100\n",
            "66/66 - 34s - loss: 0.4707 - accuracy: 0.3130 - val_loss: 0.8127 - val_accuracy: 0.1207\n",
            "Epoch 8/100\n",
            "66/66 - 35s - loss: 0.4419 - accuracy: 0.3151 - val_loss: 0.6013 - val_accuracy: 0.2185\n",
            "Epoch 9/100\n",
            "66/66 - 34s - loss: 0.4215 - accuracy: 0.3130 - val_loss: 0.5352 - val_accuracy: 0.2528\n",
            "Epoch 10/100\n",
            "66/66 - 35s - loss: 0.3986 - accuracy: 0.3133 - val_loss: 0.4864 - val_accuracy: 0.2825\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3848 - accuracy: 0.3106 - val_loss: 0.4523 - val_accuracy: 0.3187\n",
            "Epoch 12/100\n",
            "66/66 - 35s - loss: 0.3557 - accuracy: 0.3102 - val_loss: 0.4518 - val_accuracy: 0.3350\n",
            "Epoch 13/100\n",
            "66/66 - 34s - loss: 0.3374 - accuracy: 0.3102 - val_loss: 0.4733 - val_accuracy: 0.2937\n",
            "Epoch 14/100\n",
            "66/66 - 35s - loss: 0.3175 - accuracy: 0.3091 - val_loss: 0.4646 - val_accuracy: 0.3391\n",
            "Epoch 15/100\n",
            "66/66 - 34s - loss: 0.2975 - accuracy: 0.3084 - val_loss: 0.4718 - val_accuracy: 0.2860\n",
            "Epoch 16/100\n",
            "66/66 - 35s - loss: 0.2839 - accuracy: 0.3086 - val_loss: 0.4570 - val_accuracy: 0.2881\n",
            "Epoch 17/100\n",
            "66/66 - 34s - loss: 0.2558 - accuracy: 0.3074 - val_loss: 0.4774 - val_accuracy: 0.2983\n",
            "Epoch 18/100\n",
            "66/66 - 35s - loss: 0.2541 - accuracy: 0.3071 - val_loss: 0.5298 - val_accuracy: 0.3437\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2356 - accuracy: 0.3063 - val_loss: 0.5736 - val_accuracy: 0.2452\n",
            "Epoch 20/100\n",
            "66/66 - 34s - loss: 0.2291 - accuracy: 0.3062 - val_loss: 0.5581 - val_accuracy: 0.3209\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2176 - accuracy: 0.3053 - val_loss: 0.6688 - val_accuracy: 0.2319\n",
            "Epoch 22/100\n",
            "66/66 - 35s - loss: 0.2062 - accuracy: 0.3051 - val_loss: 0.5913 - val_accuracy: 0.2847\n",
            "10/10 [==============================] - 4s 407ms/step - loss: 0.4518 - accuracy: 0.3350\n",
            "[0.4518183171749115, 0.3350447714328766]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHGlKNuYTYnR",
        "outputId": "5a338ec7-4590-44f3-a43d-9d123593dc10"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"adam\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout enabled, then turn it off.\n",
        "starting_epochs=5\n",
        "wedge.trainable = True\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = False\n",
        "print('WedgeDropout2D disabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1315s vs `on_train_batch_end` time: 0.3104s). Check your callbacks.\n",
            "66/66 - 30s - loss: 3.6502 - accuracy: 0.3236\n",
            "Epoch 2/5\n",
            "66/66 - 31s - loss: 0.7204 - accuracy: 0.3122\n",
            "Epoch 3/5\n",
            "66/66 - 30s - loss: 0.6081 - accuracy: 0.3142\n",
            "Epoch 4/5\n",
            "66/66 - 30s - loss: 0.5647 - accuracy: 0.3142\n",
            "Epoch 5/5\n",
            "66/66 - 31s - loss: 0.5319 - accuracy: 0.3140\n",
            "WedgeDropout2D disabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1344s vs `on_train_batch_end` time: 0.3092s). Check your callbacks.\n",
            "66/66 - 35s - loss: 0.5045 - accuracy: 0.3133 - val_loss: 1.5405 - val_accuracy: 0.0026\n",
            "Epoch 7/100\n",
            "66/66 - 35s - loss: 0.4771 - accuracy: 0.3130 - val_loss: 0.9160 - val_accuracy: 0.1026\n",
            "Epoch 8/100\n",
            "66/66 - 35s - loss: 0.4493 - accuracy: 0.3126 - val_loss: 0.5576 - val_accuracy: 0.2627\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4273 - accuracy: 0.3129 - val_loss: 0.5365 - val_accuracy: 0.2473\n",
            "Epoch 10/100\n",
            "66/66 - 34s - loss: 0.4069 - accuracy: 0.3118 - val_loss: 0.4567 - val_accuracy: 0.3269\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3844 - accuracy: 0.3114 - val_loss: 0.5262 - val_accuracy: 0.2323\n",
            "Epoch 12/100\n",
            "66/66 - 34s - loss: 0.3653 - accuracy: 0.3113 - val_loss: 0.4485 - val_accuracy: 0.3459\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3425 - accuracy: 0.3101 - val_loss: 0.4811 - val_accuracy: 0.3227\n",
            "Epoch 14/100\n",
            "66/66 - 34s - loss: 0.3315 - accuracy: 0.3101 - val_loss: 0.4624 - val_accuracy: 0.3375\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.3090 - accuracy: 0.3085 - val_loss: 0.4527 - val_accuracy: 0.3027\n",
            "Epoch 16/100\n",
            "66/66 - 35s - loss: 0.2931 - accuracy: 0.3084 - val_loss: 0.4426 - val_accuracy: 0.3048\n",
            "Epoch 17/100\n",
            "66/66 - 35s - loss: 0.2699 - accuracy: 0.3081 - val_loss: 0.5203 - val_accuracy: 0.2429\n",
            "Epoch 18/100\n",
            "66/66 - 35s - loss: 0.2648 - accuracy: 0.3069 - val_loss: 0.5020 - val_accuracy: 0.3474\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2482 - accuracy: 0.3065 - val_loss: 0.5053 - val_accuracy: 0.2985\n",
            "Epoch 20/100\n",
            "66/66 - 35s - loss: 0.2277 - accuracy: 0.3060 - val_loss: 0.6892 - val_accuracy: 0.2216\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2189 - accuracy: 0.3050 - val_loss: 0.5099 - val_accuracy: 0.2976\n",
            "Epoch 22/100\n",
            "66/66 - 34s - loss: 0.2179 - accuracy: 0.3049 - val_loss: 0.5920 - val_accuracy: 0.2507\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2064 - accuracy: 0.3048 - val_loss: 0.5290 - val_accuracy: 0.2866\n",
            "Epoch 24/100\n",
            "66/66 - 34s - loss: 0.1907 - accuracy: 0.3038 - val_loss: 0.5573 - val_accuracy: 0.2544\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.1846 - accuracy: 0.3028 - val_loss: 0.5694 - val_accuracy: 0.3129\n",
            "Epoch 26/100\n",
            "66/66 - 35s - loss: 0.1764 - accuracy: 0.3031 - val_loss: 0.6407 - val_accuracy: 0.2677\n",
            "10/10 [==============================] - 4s 387ms/step - loss: 0.4426 - accuracy: 0.3048\n",
            "[0.4425504505634308, 0.304808646440506]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2xwBorVZ9Wq"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}