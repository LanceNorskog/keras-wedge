{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wedge- oxford_pets_image_segmentation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hagnL1_ktELY"
      },
      "source": [
        "# Image segmentation with a U-Net-like architecture\n",
        "Rebuilt to demo validity of Wedge Dropout, and compare it to Spatial Dropout.\n",
        "\n",
        "Original is: https://keras.io/examples/vision/oxford_pets_image_segmentation/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C98e--9mVYD4",
        "outputId": "cf987e00-7038-4c9a-e899-c3c61777ee07"
      },
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install -q tensorflow==2.3.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.5.0\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "\u001b[K     |████████████████████████████████| 320.5 MB 14 kB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 69.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 459 kB 74.4 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpmOjiHIxLdv"
      },
      "source": [
        "!wget -q -nc http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget -q -nc http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6x42FhkxLdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7ed3a8-adaa-4413-af27-6a281c9e6fe5"
      },
      "source": [
        "import os\n",
        "\n",
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "img_size = (160, 160)\n",
        "num_classes = 4\n",
        "batch_size = 96\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
        "    print(input_path, \"|\", target_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 7390\n",
            "images/Abyssinian_1.jpg | annotations/trimaps/Abyssinian_1.png\n",
            "images/Abyssinian_10.jpg | annotations/trimaps/Abyssinian_10.png\n",
            "images/Abyssinian_100.jpg | annotations/trimaps/Abyssinian_100.png\n",
            "images/Abyssinian_101.jpg | annotations/trimaps/Abyssinian_101.png\n",
            "images/Abyssinian_102.jpg | annotations/trimaps/Abyssinian_102.png\n",
            "images/Abyssinian_103.jpg | annotations/trimaps/Abyssinian_103.png\n",
            "images/Abyssinian_104.jpg | annotations/trimaps/Abyssinian_104.png\n",
            "images/Abyssinian_105.jpg | annotations/trimaps/Abyssinian_105.png\n",
            "images/Abyssinian_106.jpg | annotations/trimaps/Abyssinian_106.png\n",
            "images/Abyssinian_107.jpg | annotations/trimaps/Abyssinian_107.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er0hnZpqxLd7"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "class OxfordPets(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size)\n",
        "            x[j] = img\n",
        "        y = np.zeros((batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
        "            y[j] = np.expand_dims(img, 2)\n",
        "        return x / 255, y - 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl81iFvqOUig"
      },
      "source": [
        "# Wedge2D Dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fN0dcOM-Xyy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D897MxAgv8Fy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1449513b-681a-43bc-e25d-6551dc2d1684"
      },
      "source": [
        "!pip uninstall -y keras-wedge-dropout\n",
        "!pip install -q git+https://github.com/LanceNorskog/keras-wedge.git\n",
        "import numpy as np\n",
        "from keras_wedge_dropout import WedgeDropout2D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping keras-wedge-dropout as it is not installed.\u001b[0m\n",
            "  Building wheel for keras-wedge-dropout (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzrKgPOkxLd-"
      },
      "source": [
        "## Perpare U-Net Xception-style model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncweKfbxLd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f9388b-66c0-43d6-c410-05aab80c7cbe"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "he = 'he_normal'\n",
        "def get_model(img_size, num_classes, wedgeDropout=False):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\", kernel_initializer = he)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for step, filters in enumerate([64, 128, 256]):\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\", kernel_initializer = he)(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for step, filters in enumerate([256, 128, 64, 32]):\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\", kernel_initializer = he)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\", kernel_initializer = he)(residual)\n",
        "        x = layers.add([x, residual], name='final_add_'+str(step))  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    wedge = None\n",
        "    if wedgeDropout:\n",
        "        x = WedgeDropout2D(0.65, batchwise=True, norm=True)(x)\n",
        "        wedge = x\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\", name='output', kernel_initializer = he)(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model, wedge\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model, _ = get_model(img_size, num_classes)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        final_add_3[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR243W93xLeC"
      },
      "source": [
        "## Set aside a validation split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCCk3rxuxLeC"
      },
      "source": [
        "import random\n",
        "\n",
        "# Split our img paths into a training and a validation set\n",
        "val_samples = 1000\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_img_paths)\n",
        "train_input_img_paths = input_img_paths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_img_paths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = OxfordPets(\n",
        "    batch_size, img_size, train_input_img_paths, train_target_img_paths\n",
        ")\n",
        "val_gen = OxfordPets(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD_s4NmSxLeG"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PfqUOM3xLeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f385371c-1337-4850-8fea-f59ae892800e"
      },
      "source": [
        "# Configure the model for training.\n",
        "# We use the \"sparse\" version of categorical_crossentropy\n",
        "# because our target data is integers.\n",
        "model.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 100\n",
        "model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model.evaluate(val_gen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1084s vs `on_train_batch_end` time: 0.3220s). Check your callbacks.\n",
            "66/66 - 36s - loss: 4.1725 - accuracy: 0.3018 - val_loss: 5.1031 - val_accuracy: 0.0101\n",
            "Epoch 2/100\n",
            "66/66 - 35s - loss: 0.8967 - accuracy: 0.3046 - val_loss: 1.6175 - val_accuracy: 0.0915\n",
            "Epoch 3/100\n",
            "66/66 - 33s - loss: 0.7542 - accuracy: 0.3058 - val_loss: 1.5730 - val_accuracy: 2.9553e-04\n",
            "Epoch 4/100\n",
            "66/66 - 34s - loss: 0.6245 - accuracy: 0.3135 - val_loss: 1.3110 - val_accuracy: 6.3745e-04\n",
            "Epoch 5/100\n",
            "66/66 - 33s - loss: 0.5496 - accuracy: 0.3099 - val_loss: 1.1826 - val_accuracy: 0.0071\n",
            "Epoch 6/100\n",
            "66/66 - 35s - loss: 0.4955 - accuracy: 0.3081 - val_loss: 0.8450 - val_accuracy: 0.0588\n",
            "Epoch 7/100\n",
            "66/66 - 33s - loss: 0.4660 - accuracy: 0.3107 - val_loss: 0.5835 - val_accuracy: 0.2210\n",
            "Epoch 8/100\n",
            "66/66 - 35s - loss: 0.4230 - accuracy: 0.3090 - val_loss: 0.4825 - val_accuracy: 0.2514\n",
            "Epoch 9/100\n",
            "66/66 - 33s - loss: 0.4007 - accuracy: 0.3103 - val_loss: 0.4455 - val_accuracy: 0.2948\n",
            "Epoch 10/100\n",
            "66/66 - 35s - loss: 0.3907 - accuracy: 0.3089 - val_loss: 0.4763 - val_accuracy: 0.2615\n",
            "Epoch 11/100\n",
            "66/66 - 34s - loss: 0.3471 - accuracy: 0.3087 - val_loss: 0.4175 - val_accuracy: 0.3381\n",
            "Epoch 12/100\n",
            "66/66 - 34s - loss: 0.3338 - accuracy: 0.3083 - val_loss: 0.4421 - val_accuracy: 0.2972\n",
            "Epoch 13/100\n",
            "66/66 - 34s - loss: 0.3139 - accuracy: 0.3074 - val_loss: 0.4194 - val_accuracy: 0.3127\n",
            "Epoch 14/100\n",
            "66/66 - 34s - loss: 0.2995 - accuracy: 0.3071 - val_loss: 0.4046 - val_accuracy: 0.3018\n",
            "Epoch 15/100\n",
            "66/66 - 34s - loss: 0.2761 - accuracy: 0.3070 - val_loss: 0.4167 - val_accuracy: 0.3064\n",
            "Epoch 16/100\n",
            "66/66 - 34s - loss: 0.2655 - accuracy: 0.3062 - val_loss: 0.4659 - val_accuracy: 0.3151\n",
            "Epoch 17/100\n",
            "66/66 - 34s - loss: 0.2492 - accuracy: 0.3060 - val_loss: 0.4433 - val_accuracy: 0.3108\n",
            "Epoch 18/100\n",
            "66/66 - 34s - loss: 0.2331 - accuracy: 0.3056 - val_loss: 0.4410 - val_accuracy: 0.2771\n",
            "Epoch 19/100\n",
            "66/66 - 33s - loss: 0.3263 - accuracy: 0.3051 - val_loss: 0.4225 - val_accuracy: 0.2988\n",
            "Epoch 20/100\n",
            "66/66 - 34s - loss: 0.2212 - accuracy: 0.3048 - val_loss: 0.5006 - val_accuracy: 0.2761\n",
            "Epoch 21/100\n",
            "66/66 - 34s - loss: 0.2121 - accuracy: 0.3043 - val_loss: 0.5044 - val_accuracy: 0.2659\n",
            "Epoch 22/100\n",
            "66/66 - 33s - loss: 0.2063 - accuracy: 0.3037 - val_loss: 0.5688 - val_accuracy: 0.3471\n",
            "Epoch 23/100\n",
            "66/66 - 34s - loss: 0.2037 - accuracy: 0.3034 - val_loss: 0.5927 - val_accuracy: 0.3428\n",
            "Epoch 24/100\n",
            "66/66 - 33s - loss: 0.1917 - accuracy: 0.3032 - val_loss: 0.5327 - val_accuracy: 0.2800\n",
            "10/10 [==============================] - 4s 412ms/step - loss: 0.4046 - accuracy: 0.3018\n",
            "[0.4045927822589874, 0.3018067479133606]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TqNBziQPTrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942ff385-eb3d-49ae-8b5e-af3bde059eed"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, _ = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch.\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1280s vs `on_train_batch_end` time: 0.3240s). Check your callbacks.\n",
            "66/66 - 37s - loss: 4.9527 - accuracy: 0.2543 - val_loss: 6.6973 - val_accuracy: 6.3354e-05\n",
            "Epoch 2/100\n",
            "66/66 - 36s - loss: 1.7347 - accuracy: 0.3057 - val_loss: 2.9009 - val_accuracy: 3.8212e-04\n",
            "Epoch 3/100\n",
            "66/66 - 35s - loss: 0.8245 - accuracy: 0.3063 - val_loss: 1.5326 - val_accuracy: 0.0014\n",
            "Epoch 4/100\n",
            "66/66 - 36s - loss: 0.6151 - accuracy: 0.3062 - val_loss: 1.3380 - val_accuracy: 0.0012\n",
            "Epoch 5/100\n",
            "66/66 - 35s - loss: 0.5781 - accuracy: 0.3073 - val_loss: 1.3974 - val_accuracy: 0.0022\n",
            "Epoch 6/100\n",
            "66/66 - 36s - loss: 0.5088 - accuracy: 0.3140 - val_loss: 1.3151 - val_accuracy: 0.0125\n",
            "Epoch 7/100\n",
            "66/66 - 35s - loss: 0.4718 - accuracy: 0.3106 - val_loss: 0.7620 - val_accuracy: 0.1299\n",
            "Epoch 8/100\n",
            "66/66 - 36s - loss: 0.4396 - accuracy: 0.3100 - val_loss: 0.5423 - val_accuracy: 0.3750\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4255 - accuracy: 0.3103 - val_loss: 0.5052 - val_accuracy: 0.3630\n",
            "Epoch 10/100\n",
            "66/66 - 36s - loss: 0.3897 - accuracy: 0.3102 - val_loss: 0.4295 - val_accuracy: 0.3064\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3776 - accuracy: 0.3088 - val_loss: 0.4852 - val_accuracy: 0.2203\n",
            "Epoch 12/100\n",
            "66/66 - 35s - loss: 0.3553 - accuracy: 0.3097 - val_loss: 0.4795 - val_accuracy: 0.3800\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3306 - accuracy: 0.3093 - val_loss: 0.4553 - val_accuracy: 0.2807\n",
            "Epoch 14/100\n",
            "66/66 - 36s - loss: 0.3105 - accuracy: 0.3081 - val_loss: 0.4223 - val_accuracy: 0.3182\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.3037 - accuracy: 0.3069 - val_loss: 0.4180 - val_accuracy: 0.3326\n",
            "Epoch 16/100\n",
            "66/66 - 36s - loss: 0.2935 - accuracy: 0.3055 - val_loss: 0.4314 - val_accuracy: 0.3217\n",
            "Epoch 17/100\n",
            "66/66 - 35s - loss: 0.2683 - accuracy: 0.3069 - val_loss: 0.4722 - val_accuracy: 0.2761\n",
            "Epoch 18/100\n",
            "66/66 - 36s - loss: 0.2593 - accuracy: 0.3058 - val_loss: 0.4388 - val_accuracy: 0.3122\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2469 - accuracy: 0.3060 - val_loss: 0.4830 - val_accuracy: 0.3062\n",
            "Epoch 20/100\n",
            "66/66 - 36s - loss: 0.2382 - accuracy: 0.3050 - val_loss: 0.5359 - val_accuracy: 0.3202\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2275 - accuracy: 0.3058 - val_loss: 0.4926 - val_accuracy: 0.2914\n",
            "Epoch 22/100\n",
            "66/66 - 35s - loss: 0.2199 - accuracy: 0.3048 - val_loss: 0.4666 - val_accuracy: 0.3112\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2103 - accuracy: 0.3043 - val_loss: 0.4784 - val_accuracy: 0.2906\n",
            "Epoch 24/100\n",
            "66/66 - 35s - loss: 0.1995 - accuracy: 0.3039 - val_loss: 0.5184 - val_accuracy: 0.2756\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.1983 - accuracy: 0.3034 - val_loss: 0.5113 - val_accuracy: 0.2690\n",
            "10/10 [==============================] - 4s 396ms/step - loss: 0.4180 - accuracy: 0.3326\n",
            "[0.41798141598701477, 0.33257463574409485]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869amnT6-3Zk",
        "outputId": "a92c927a-93fc-4ca1-9e96-e13becc744b8"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"rmsprop\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout disabled, then turn it on.\n",
        "starting_epochs=5\n",
        "wedge.trainable = False\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = True\n",
        "print('WedgeDropout2D enabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "66/66 - 32s - loss: 4.7555 - accuracy: 0.2816\n",
            "Epoch 2/5\n",
            "66/66 - 31s - loss: 1.1382 - accuracy: 0.3082\n",
            "Epoch 3/5\n",
            "66/66 - 32s - loss: 0.7569 - accuracy: 0.3157\n",
            "Epoch 4/5\n",
            "66/66 - 32s - loss: 0.6331 - accuracy: 0.3190\n",
            "Epoch 5/5\n",
            "66/66 - 30s - loss: 0.5677 - accuracy: 0.3150\n",
            "WedgeDropout2D enabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1282s vs `on_train_batch_end` time: 0.3223s). Check your callbacks.\n",
            "66/66 - 37s - loss: 0.5136 - accuracy: 0.3090 - val_loss: 0.9733 - val_accuracy: 0.0371\n",
            "Epoch 7/100\n",
            "66/66 - 34s - loss: 0.4887 - accuracy: 0.3093 - val_loss: 0.5879 - val_accuracy: 0.2042\n",
            "Epoch 8/100\n",
            "66/66 - 36s - loss: 0.4476 - accuracy: 0.3127 - val_loss: 0.5115 - val_accuracy: 0.3219\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4183 - accuracy: 0.3121 - val_loss: 0.4964 - val_accuracy: 0.2523\n",
            "Epoch 10/100\n",
            "66/66 - 35s - loss: 0.3922 - accuracy: 0.3112 - val_loss: 0.4164 - val_accuracy: 0.3362\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.3757 - accuracy: 0.3089 - val_loss: 0.4374 - val_accuracy: 0.3197\n",
            "Epoch 12/100\n",
            "66/66 - 35s - loss: 0.3485 - accuracy: 0.3102 - val_loss: 0.4459 - val_accuracy: 0.2920\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3301 - accuracy: 0.3083 - val_loss: 0.4330 - val_accuracy: 0.3295\n",
            "Epoch 14/100\n",
            "66/66 - 36s - loss: 0.3105 - accuracy: 0.3088 - val_loss: 0.5018 - val_accuracy: 0.2578\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.2904 - accuracy: 0.3087 - val_loss: 0.4155 - val_accuracy: 0.3161\n",
            "Epoch 16/100\n",
            "66/66 - 35s - loss: 0.2841 - accuracy: 0.3063 - val_loss: 0.4322 - val_accuracy: 0.2921\n",
            "Epoch 17/100\n",
            "66/66 - 34s - loss: 0.2663 - accuracy: 0.3073 - val_loss: 0.4345 - val_accuracy: 0.2897\n",
            "Epoch 18/100\n",
            "66/66 - 36s - loss: 0.2557 - accuracy: 0.3065 - val_loss: 0.4356 - val_accuracy: 0.3032\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2469 - accuracy: 0.3058 - val_loss: 0.4912 - val_accuracy: 0.2916\n",
            "Epoch 20/100\n",
            "66/66 - 35s - loss: 0.2312 - accuracy: 0.3056 - val_loss: 0.4508 - val_accuracy: 0.3208\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2273 - accuracy: 0.3055 - val_loss: 0.4304 - val_accuracy: 0.3249\n",
            "Epoch 22/100\n",
            "66/66 - 36s - loss: 0.2235 - accuracy: 0.3052 - val_loss: 0.4475 - val_accuracy: 0.2958\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2027 - accuracy: 0.3044 - val_loss: 0.5084 - val_accuracy: 0.3029\n",
            "Epoch 24/100\n",
            "66/66 - 35s - loss: 0.2173 - accuracy: 0.3037 - val_loss: 0.4487 - val_accuracy: 0.2921\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.1957 - accuracy: 0.3030 - val_loss: 0.4756 - val_accuracy: 0.2837\n",
            "10/10 [==============================] - 4s 402ms/step - loss: 0.4155 - accuracy: 0.3161\n",
            "[0.4154546856880188, 0.3161288797855377]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUqYFn5TtXmJ",
        "outputId": "3b2c3741-a6cc-4a2b-e8f8-b70d37530ead"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"adam\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout disabled, then turn it on.\n",
        "starting_epochs=5\n",
        "wedge.trainable = False\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = True\n",
        "print('WedgeDropout2D enabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1304s vs `on_train_batch_end` time: 0.3070s). Check your callbacks.\n",
            "66/66 - 31s - loss: 6.0188 - accuracy: 0.1665\n",
            "Epoch 2/5\n",
            "66/66 - 30s - loss: 1.7410 - accuracy: 0.3065\n",
            "Epoch 3/5\n",
            "66/66 - 31s - loss: 0.6571 - accuracy: 0.3163\n",
            "Epoch 4/5\n",
            "66/66 - 30s - loss: 0.5902 - accuracy: 0.3186\n",
            "Epoch 5/5\n",
            "66/66 - 32s - loss: 0.5726 - accuracy: 0.3110\n",
            "WedgeDropout2D enabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1619s vs `on_train_batch_end` time: 0.3231s). Check your callbacks.\n",
            "66/66 - 37s - loss: 0.5310 - accuracy: 0.3146 - val_loss: 1.0609 - val_accuracy: 0.0112\n",
            "Epoch 7/100\n",
            "66/66 - 35s - loss: 0.5017 - accuracy: 0.3145 - val_loss: 0.7221 - val_accuracy: 0.1015\n",
            "Epoch 8/100\n",
            "66/66 - 36s - loss: 0.4731 - accuracy: 0.3146 - val_loss: 0.6042 - val_accuracy: 0.1855\n",
            "Epoch 9/100\n",
            "66/66 - 35s - loss: 0.4501 - accuracy: 0.3132 - val_loss: 0.5206 - val_accuracy: 0.2430\n",
            "Epoch 10/100\n",
            "66/66 - 35s - loss: 0.4314 - accuracy: 0.3127 - val_loss: 0.4806 - val_accuracy: 0.3500\n",
            "Epoch 11/100\n",
            "66/66 - 35s - loss: 0.4098 - accuracy: 0.3136 - val_loss: 0.4738 - val_accuracy: 0.2571\n",
            "Epoch 12/100\n",
            "66/66 - 35s - loss: 0.3944 - accuracy: 0.3131 - val_loss: 0.4535 - val_accuracy: 0.2811\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3734 - accuracy: 0.3104 - val_loss: 0.4401 - val_accuracy: 0.3244\n",
            "Epoch 14/100\n",
            "66/66 - 35s - loss: 0.3509 - accuracy: 0.3109 - val_loss: 0.4647 - val_accuracy: 0.3027\n",
            "Epoch 15/100\n",
            "66/66 - 36s - loss: 0.3442 - accuracy: 0.3115 - val_loss: 0.4422 - val_accuracy: 0.2747\n",
            "Epoch 16/100\n",
            "66/66 - 36s - loss: 0.3239 - accuracy: 0.3105 - val_loss: 0.4837 - val_accuracy: 0.3742\n",
            "Epoch 17/100\n",
            "66/66 - 34s - loss: 0.2986 - accuracy: 0.3096 - val_loss: 0.4428 - val_accuracy: 0.2935\n",
            "Epoch 18/100\n",
            "66/66 - 36s - loss: 0.2943 - accuracy: 0.3091 - val_loss: 0.5035 - val_accuracy: 0.2651\n",
            "Epoch 19/100\n",
            "66/66 - 35s - loss: 0.2772 - accuracy: 0.3092 - val_loss: 0.5514 - val_accuracy: 0.2802\n",
            "Epoch 20/100\n",
            "66/66 - 35s - loss: 0.2565 - accuracy: 0.3080 - val_loss: 0.4934 - val_accuracy: 0.2999\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2452 - accuracy: 0.3082 - val_loss: 0.4884 - val_accuracy: 0.2730\n",
            "Epoch 22/100\n",
            "66/66 - 35s - loss: 0.2287 - accuracy: 0.3067 - val_loss: 0.5213 - val_accuracy: 0.2820\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2292 - accuracy: 0.3067 - val_loss: 0.5216 - val_accuracy: 0.3226\n",
            "10/10 [==============================] - 4s 420ms/step - loss: 0.4401 - accuracy: 0.3244\n",
            "[0.44007205963134766, 0.32437431812286377]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHGlKNuYTYnR",
        "outputId": "36faae36-4d27-4cb2-900e-61591631bee3"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model_wedge, wedge = get_model(img_size, num_classes, wedgeDropout=True)\n",
        "model_wedge.summary()\n",
        "\n",
        "model_wedge.compile(optimizer=\"adam\", \n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Do 5 epochs with WedgeDropout enabled, then turn it off.\n",
        "starting_epochs=5\n",
        "wedge.trainable = True\n",
        "model_wedge.fit(train_gen, epochs=starting_epochs, verbose=2)\n",
        "wedge.trainable = False\n",
        "print('WedgeDropout2D disabled')\n",
        "epochs = 100\n",
        "model_wedge.fit(train_gen, initial_epoch=starting_epochs, epochs=epochs, validation_data=val_gen, callbacks=callbacks, verbose=2)\n",
        "print(model_wedge.evaluate(val_gen))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WedgeDropout2D.build: input_shape: (None, 160, 160, 32)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 80, 80, 32)   896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 80, 80, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 80, 80, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 80, 80, 64)   2400        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 80, 80, 64)   256         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 80, 80, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 80, 80, 64)   4736        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 80, 80, 64)   256         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 40, 40, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 64)   2112        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 40, 40, 64)   0           max_pooling2d[0][0]              \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 40, 40, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 40, 40, 128)  8896        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 40, 40, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 40, 40, 128)  17664       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 128)  512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 20, 20, 128)  8320        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 20, 20, 128)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 20, 20, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 20, 20, 256)  34176       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 20, 20, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 20, 20, 256)  68096       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 20, 20, 256)  1024        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 10, 10, 256)  33024       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 10, 10, 256)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 10, 10, 256)  590080      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 10, 10, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 10, 10, 256)  590080      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 10, 10, 256)  1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 20, 20, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 20, 20, 256)  65792       up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_0 (Add)               (None, 20, 20, 256)  0           up_sampling2d[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 20, 20, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 20, 20, 128)  295040      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 20, 20, 128)  512         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 20, 20, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 20, 20, 128)  147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 20, 20, 128)  512         conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 40, 40, 256)  0           final_add_0[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 128)  32896       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_1 (Add)               (None, 40, 40, 128)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 40, 40, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 40, 40, 64)   73792       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 40, 40, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 40, 40, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 40, 40, 64)   256         conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 80, 80, 128)  0           final_add_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 80, 80, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 80, 80, 64)   8256        up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_2 (Add)               (None, 80, 80, 64)   0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 80, 80, 64)   0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 80, 80, 32)   18464       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 80, 80, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 80, 80, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 80, 80, 32)   128         conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 160, 160, 64) 0           final_add_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 160, 160, 32) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 160, 160, 32) 2080        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "final_add_3 (Add)               (None, 160, 160, 32) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "wedge_dropout2d (WedgeDropout2D (None, 160, 160, 32) 0           final_add_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Conv2D)                 (None, 160, 160, 4)  1156        wedge_dropout2d[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,059,268\n",
            "Trainable params: 2,055,492\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1252s vs `on_train_batch_end` time: 0.3246s). Check your callbacks.\n",
            "66/66 - 31s - loss: 3.9511 - accuracy: 0.3435\n",
            "Epoch 2/5\n",
            "66/66 - 31s - loss: 1.8346 - accuracy: 0.3204\n",
            "Epoch 3/5\n",
            "66/66 - 31s - loss: 0.6746 - accuracy: 0.3207\n",
            "Epoch 4/5\n",
            "66/66 - 30s - loss: 0.6105 - accuracy: 0.3196\n",
            "Epoch 5/5\n",
            "66/66 - 31s - loss: 0.5983 - accuracy: 0.3183\n",
            "WedgeDropout2D disabled\n",
            "Epoch 6/100\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1315s vs `on_train_batch_end` time: 0.3229s). Check your callbacks.\n",
            "66/66 - 36s - loss: 0.5585 - accuracy: 0.3184 - val_loss: 1.1596 - val_accuracy: 0.0076\n",
            "Epoch 7/100\n",
            "66/66 - 36s - loss: 0.5402 - accuracy: 0.3125 - val_loss: 0.8468 - val_accuracy: 0.0589\n",
            "Epoch 8/100\n",
            "66/66 - 35s - loss: 0.4927 - accuracy: 0.3164 - val_loss: 0.6191 - val_accuracy: 0.2136\n",
            "Epoch 9/100\n",
            "66/66 - 36s - loss: 0.4633 - accuracy: 0.3157 - val_loss: 0.5812 - val_accuracy: 0.2136\n",
            "Epoch 10/100\n",
            "66/66 - 34s - loss: 0.4473 - accuracy: 0.3156 - val_loss: 0.4859 - val_accuracy: 0.2971\n",
            "Epoch 11/100\n",
            "66/66 - 36s - loss: 0.4195 - accuracy: 0.3150 - val_loss: 0.4812 - val_accuracy: 0.3601\n",
            "Epoch 12/100\n",
            "66/66 - 35s - loss: 0.4108 - accuracy: 0.3139 - val_loss: 0.4610 - val_accuracy: 0.3311\n",
            "Epoch 13/100\n",
            "66/66 - 35s - loss: 0.3902 - accuracy: 0.3127 - val_loss: 0.4940 - val_accuracy: 0.2594\n",
            "Epoch 14/100\n",
            "66/66 - 35s - loss: 0.3681 - accuracy: 0.3124 - val_loss: 0.5653 - val_accuracy: 0.4012\n",
            "Epoch 15/100\n",
            "66/66 - 35s - loss: 0.3516 - accuracy: 0.3105 - val_loss: 0.4609 - val_accuracy: 0.3009\n",
            "Epoch 16/100\n",
            "66/66 - 35s - loss: 0.3245 - accuracy: 0.3113 - val_loss: 0.4479 - val_accuracy: 0.3034\n",
            "Epoch 17/100\n",
            "66/66 - 36s - loss: 0.3150 - accuracy: 0.3096 - val_loss: 0.4757 - val_accuracy: 0.2778\n",
            "Epoch 18/100\n",
            "66/66 - 34s - loss: 0.2892 - accuracy: 0.3095 - val_loss: 0.4609 - val_accuracy: 0.3154\n",
            "Epoch 19/100\n",
            "66/66 - 36s - loss: 0.2756 - accuracy: 0.3089 - val_loss: 0.4909 - val_accuracy: 0.3324\n",
            "Epoch 20/100\n",
            "66/66 - 36s - loss: 0.2592 - accuracy: 0.3076 - val_loss: 0.5674 - val_accuracy: 0.3602\n",
            "Epoch 21/100\n",
            "66/66 - 35s - loss: 0.2627 - accuracy: 0.3081 - val_loss: 0.5321 - val_accuracy: 0.3203\n",
            "Epoch 22/100\n",
            "66/66 - 36s - loss: 0.2461 - accuracy: 0.3067 - val_loss: 0.6392 - val_accuracy: 0.2607\n",
            "Epoch 23/100\n",
            "66/66 - 35s - loss: 0.2343 - accuracy: 0.3063 - val_loss: 0.5317 - val_accuracy: 0.3309\n",
            "Epoch 24/100\n",
            "66/66 - 35s - loss: 0.2185 - accuracy: 0.3061 - val_loss: 0.5021 - val_accuracy: 0.2899\n",
            "Epoch 25/100\n",
            "66/66 - 35s - loss: 0.2033 - accuracy: 0.3049 - val_loss: 0.6272 - val_accuracy: 0.2408\n",
            "Epoch 26/100\n",
            "66/66 - 35s - loss: 0.2110 - accuracy: 0.3045 - val_loss: 0.6311 - val_accuracy: 0.3124\n",
            "10/10 [==============================] - 4s 401ms/step - loss: 0.4479 - accuracy: 0.3034\n",
            "[0.44794711470603943, 0.30340221524238586]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2xwBorVZ9Wq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
